{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text with the saved weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script I'll use the before saved model parameters (especially the weights) to make text predictionts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text and convert to lowercase\n",
    "filename = \"./input/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique charst to integers and reverse\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c,i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", str(n_chars))\n",
    "print(\"Total distinct characters: \", str(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "seq_length = 100\n",
    "trainX = []\n",
    "trainY = []\n",
    "for i in range(0, n_chars-seq_length, 1):\n",
    "    seq_in = raw_text[i : i + seq_length]   # in 1st iteration contains first 100 chars\n",
    "    seq_out = raw_text[i + seq_length]   # in 1st iteration contains 101st char\n",
    "    trainX.append([char_to_int[char] for char in seq_in])   # char is the character as string, char_to_int[char] gives the int value\n",
    "    trainX\n",
    "    trainY.append(char_to_int[seq_out])\n",
    "n_patterns = len(trainX)\n",
    "print(\"Total # of Patterns: \" + str(n_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to [samples, time steps, features]\n",
    "X = np.reshape(trainX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one-hot encode y\n",
    "y = np_utils.to_categorical(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "filename = \"\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a random integer between 0 and the number of different patterns in the training data\n",
    "start = np.random.randint(0, len(trainX)-1)\n",
    "# pick the random pattern\n",
    "pattern = trainX[start]\n",
    "print(\"Seed: \")\n",
    "# print the random pattern by converting the integers to characater\n",
    "print(\"\\\"\", \"\".join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty list for the result_output\n",
    "result_output = []\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    # prediction contains the probability for each character (0-45) for the given input pattern x\n",
    "    prediction = model.predict(x, verbose = 0)\n",
    "    # index contains the index where the prediction is highest\n",
    "    index = np.argmax(prediction)\n",
    "    # the predicted character\n",
    "    result = int_to_char[index]\n",
    "    # the input sequence \n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    # append predicted index to the result_output list\n",
    "    result_output.append(index)\n",
    "    # append predicted index to the pattern\n",
    "    pattern.append(index)\n",
    "    # new pattern is the old pattern with the first character cut away and the new prediction appended to the end. this new pattern is the input for the next iteration\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output/prediction.txt\", \"w\") as f:\n",
    "    f.write(\"\".join([int_to_char[value] for value in result_output]))\n",
    "    print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
